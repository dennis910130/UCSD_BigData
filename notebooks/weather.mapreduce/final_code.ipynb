{
 "metadata": {
  "name": "",
  "signature": "sha256:1fb08408b635b77a40b777dbbd7344be849de2d2f5d2a90ea8dc7115864a65d7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import pickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "home_dir='/home/ubuntu/UCSD_BigData'\n",
      "sys.path.append(home_dir+'/utils')\n",
      "from find_waiting_flow import *\n",
      "from AWS_keypair_management import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "Creds= pickle.load(open('/home/ubuntu/Vault/Creds.pkl','rb'))\n",
      "print Creds.keys()\n",
      "print Creds['mrjob'].keys()\n",
      "pair=Creds['mrjob']\n",
      "key_id=pair['key_id']\n",
      "secret_key=pair['secret_key']\n",
      "ID=pair['ID']\n",
      "print ID,key_id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['launcher', 'mrjob']\n",
        "['key_id', 'secret_key', 's3_logs', 'ID', 's3_scratch']\n",
        "364722522805 AKIAJTQ5VZL4EXWPXY2A\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "job_flow_id=find_waiting_flow(key_id,secret_key)\n",
      "job_flow_id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<boto.emr.emrobject.JobFlow object at 0x3ec8350> no_script.yoavfreund.20140611.181713.270989 j-3QZOHADZF9KY1 WAITING\n",
        "<boto.emr.emrobject.JobFlow object at 0x3ede990> no_script.yoavfreund.20140611.181722.314318 j-3MR2RR5OEXRQ7 WAITING\n",
        "<boto.emr.emrobject.JobFlow object at 0x40858d0> no_script.yoavfreund.20140611.181730.511103 j-2S5LTMBIWD2WB WAITING\n",
        "<boto.emr.emrobject.JobFlow object at 0x42ede10> no_script.yoavfreund.20140611.181738.864430 j-3TFYHEIHI9VOY WAITING\n",
        "<boto.emr.emrobject.JobFlow object at 0x454af10> no_script.yoavfreund.20140613.042333.580519 j-27Y940LIXXNSZ WAITING\n",
        "<boto.emr.emrobject.JobFlow object at 0x45e5950> no_script.yoavfreund.20140613.042344.097071 j-3LP88IFUHBOHO WAITING\n",
        "<boto.emr.emrobject.JobFlow object at 0x4607110> no_script.yoavfreund.20140613.042353.469396 j-2YMCM4F2XO00B WAITING\n",
        "<boto.emr.emrobject.JobFlow object at 0x460c1d0> no_script.yoavfreund.20140613.042403.179810 j-2DMPRXAW49U58 WAITING\n",
        "<boto.emr.emrobject.JobFlow object at 0x46d35d0> no_script.yoavfreund.20140613.154912.285351 j-1CV4WDLQKK3B6 WAITING\n",
        "<boto.emr.emrobject.JobFlow object at 0x46e29d0> no_script.yoavfreund.20140613.154922.328252 j-1XMJYZ35TFPY8 WAITING\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "u'j-1XMJYZ35TFPY8'"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile extract_valid_years.py\n",
      "#!/usr/bin/python\n",
      "\"\"\"\n",
      "count the number of valid years for each station\n",
      "\"\"\"\n",
      "import sys\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages')\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "from sys import stderr\n",
      "\n",
      "WORD_RE = re.compile(r\"[\\w']+\")\n",
      "\n",
      "class MRWeather(MRJob):\n",
      "\n",
      "    def mapper(self, _, line):\n",
      "        try:\n",
      "            self.increment_counter('MrJob Counters','mapper-all',1)\n",
      "            elements=line.split(',')\n",
      "            if (elements[1]=='TMAX' or elements[1]=='TMIN') and elements[0] != 'station':\n",
      "                Ndays = sum([e!='' for e in elements[3:]])\n",
      "                Valid_measurements = 1\n",
      "                key = (elements[0],elements[2])\n",
      "            else:\n",
      "                key = (elements[0],elements[2])\n",
      "                Valid_measurements = 0\n",
      "                Ndays = 0\n",
      "        except Exception, e:\n",
      "            stderr.write('Error in line:\\n'+line)\n",
      "            stderr.write(e)\n",
      "            self.increment_counter('MrJob Counters','mapper-error',1)\n",
      "            key = ('Error','Error')\n",
      "            Valid_measurements = 0\n",
      "            Ndays = 0\n",
      "\n",
      "        finally:\n",
      "            yield key, (Valid_measurements,Ndays)\n",
      "\n",
      "            \n",
      "    def reducer(self, word, counts):\n",
      "        self.increment_counter('MrJob Counters','reducer',1)\n",
      "        sum1 = 0\n",
      "        sum2 = 0\n",
      "        for x,y in counts:\n",
      "            sum1 = sum1 + x\n",
      "            sum2 = sum2 + y\n",
      "        if sum1 == 2 and sum2 >50:\n",
      "            yield word[0], 1\n",
      "        else:\n",
      "            yield word[0], 0\n",
      "\n",
      "    def counter(self, word, counts):\n",
      "        self.increment_counter('MrJob Counters','counter',1)\n",
      "        yield word, sum(counts)\n",
      "    \n",
      "    def steps(self):\n",
      "\n",
      "        return [self.mr(mapper=self.mapper, reducer=self.reducer),\n",
      "                self.mr(reducer=self.counter)]\n",
      "if __name__ == '__main__':\n",
      "    MRWeather.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting extract_valid_years.py\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpl_toolkits.basemap import Basemap\n",
      "\n",
      "def color_map(lon, lat, Z, figsize=(15,10), alpha=1):\n",
      "    lonmin=-180\n",
      "    lonmax=180\n",
      "    latsmin=-80\n",
      "    latsmax=80;\n",
      "    \n",
      "    plt.figure(figsize=figsize,dpi=300)\n",
      "    m = Basemap(projection='merc',llcrnrlat=latsmin,urcrnrlat=latsmax,\\\n",
      "        llcrnrlon=lonmin,urcrnrlon=lonmax,lat_ts=20,resolution='c')\n",
      "    m.drawcoastlines(color='lightgrey')\n",
      "    m.drawmapboundary()\n",
      "    \n",
      "    x,y = m(np.array(lon), np.array(lat))\n",
      "    color_map = m.scatter(x,y,c=np.array(Z),marker='.', lw=0, alpha=alpha)\n",
      "    m.colorbar(color_map)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "color_map(merged_data['longitude'], merged_data['latitude'], merged_data['valid_years'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile extract_mean_vector.py\n",
      "#!/usr/bin/python\n",
      "\"\"\"\n",
      "extract the mean vector of each station\n",
      "\"\"\"\n",
      "import sys\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages')\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "from sys import stderr\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "class MRWeather(MRJob):\n",
      "\n",
      "    def mapper(self, _, line):\n",
      "        try:      \n",
      "            self.increment_counter('MrJob Counters','mapper-all',1)\n",
      "            elements=line.split(',')\n",
      "            measure = elements[3:]\n",
      "            if (elements[1]=='TMAX') and elements[0] != 'station':\n",
      "                value = []\n",
      "                for each in measure:\n",
      "                    if each == '':\n",
      "                        value.append(np.nan)\n",
      "                    else:\n",
      "                        value.append(float(each))\n",
      "                s = pd.Series(value)\n",
      "                s = s.interpolate()\n",
      "                s = s.fillna(s.mean())\n",
      "                yield elements[0], list(s)\n",
      "                \n",
      "        except Exception, e:\n",
      "            stderr.write('Error in line:\\n'+line)\n",
      "            stderr.write(e.message)\n",
      "            self.increment_counter('MrJob Counters','mapper-error',1)\n",
      "            yield (('error','mapper', str(e)), 1)\n",
      "            \n",
      "\n",
      "            \n",
      "    def reducer(self, station, measures):\n",
      "        try:\n",
      "            temp = np.array(list(measures))\n",
      "            mean = np.rint(np.mean(temp, axis=0))\n",
      "            mean = mean.astype(int)\n",
      "            yield station, mean.tolist()[:]\n",
      "        except Exception, e:\n",
      "            yield (('error','reducer', str(e)), 1)\n",
      "\n",
      "    \n",
      "if __name__ == '__main__':\n",
      "    MRWeather.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!tr '\\t' ',' <mean_vector_l >temp_large\n",
      "!tr -d '['<temp_large >temp1_large\n",
      "!tr -d ']'<temp1_large >mean_vector_processed_large\n",
      "!rm temp_large\n",
      "!rm temp1_large"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from datetime import date\n",
      "dates=[date.fromordinal(i) for i in range(1,366)]\n",
      "def YearlyPlots(T,ttl='',size=(10,7)):\n",
      "    fig=plt.figure(1,figsize=size,dpi=300)\n",
      "    #fig, ax = plt.subplots(1)\n",
      "    if shape(T)[0] != 365:\n",
      "        raise ValueError(\"First dimension of T should be 365. Shape(T)=\"+str(shape(T)))\n",
      "    plot(dates,T);\n",
      "    # rotate and align the tick labels so they look better\n",
      "    fig.autofmt_xdate()\n",
      "    ylabel('temperature')\n",
      "    grid()\n",
      "    title(ttl)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile init_centroids.py\n",
      "#!/usr/bin/python\n",
      "import sys\n",
      "import random\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import pickle \n",
      "\n",
      "from sys import stderr\n",
      "\n",
      "from mrjob.job import MRJob\n",
      "n_centers = 10\n",
      "class find_initial_centroids(MRJob):\n",
      "    def __init__(self, args):\n",
      "        MRJob.__init__(self, args)\n",
      "        \n",
      "    def configure_options(self):\n",
      "        super(find_initial_centroids, self).configure_options()\n",
      "        self.add_passthrough_option(\n",
      "            '--k', type='int', help='Number of clusters')\n",
      "        \n",
      "    def mapper(self, _, line):\n",
      "        try:      \n",
      "            self.increment_counter('MrJob Counters','mapper-all',1)\n",
      "            elements = line.split(',')\n",
      "            \n",
      "            measure = elements[2:]\n",
      "            \"\"\"\n",
      "            value = []\n",
      "            for each in measure:\n",
      "                if each == '':\n",
      "                    value.append(np.nan)\n",
      "                else:\n",
      "                    value.append(float(each))\n",
      "            \n",
      "            s = pd.Series(value)\n",
      "            s = s.interpolate()\n",
      "            s = s.fillna(s.mean())\n",
      "            \"\"\"\n",
      "            yield None, [int(x) for x in measure]\n",
      "                \n",
      "        except Exception, e:\n",
      "            stderr.write('Error in line:\\n'+line)\n",
      "            stderr.write(e.message)\n",
      "            self.increment_counter('MrJob Counters','mapper-error',1)\n",
      "            yield (('error','mapper', str(e)), 1)\n",
      " \n",
      "    def combiner(self, _, points):\n",
      "        minp = maxp = np.array(points.next())\n",
      "        for p in points:\n",
      "            minp = np.minimum(minp, p)\n",
      "            maxp = np.maximum(maxp, p)\n",
      "        \n",
      "        yield None, minp.tolist()\n",
      "        yield None, maxp.tolist()\n",
      "      \n",
      "    def reducer(self, _, minmax):\n",
      "        minp = maxp = np.array(minmax.next(), dtype=float)\n",
      "        for p in minmax:\n",
      "            minp = np.minimum(minp, p)\n",
      "            maxp = np.maximum(maxp, p)\n",
      "        \n",
      "        k = self.options.k\n",
      "        step = (maxp-minp) / k\n",
      "        \n",
      "        \n",
      "        for i in range(k):\n",
      "            yield None, (minp + step*i).tolist()\n",
      "    \"\"\"\n",
      "    def reducer(self, _, minmax):\n",
      "        try:\n",
      "            yield None, list(minmax)\n",
      "        except Exception, e:\n",
      "            stderr.write('Error in line:\\n'+line)\n",
      "            stderr.write(e.message)\n",
      "            self.increment_counter('MrJob Counters','mapper-error',1)\n",
      "            yield (('error','mapper', str(e)), 1)\n",
      "    \"\"\"\n",
      "    \n",
      "if __name__ == '__main__':\n",
      "    find_initial_centroids.run()\n",
      "            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile update_centroids.py\n",
      "#!/usr/bin/python\n",
      "import sys\n",
      "import random\n",
      "import numpy\n",
      "import pickle\n",
      "\n",
      "from mrjob.job import MRJob\n",
      "\n",
      "\n",
      "\n",
      "class update_centroids(MRJob):\n",
      "    def configure_options(self):\n",
      "        super(update_centroids, self).configure_options()\n",
      "        self.add_passthrough_option(\n",
      "            '--k', type='int', help='Number of clusters')\n",
      "        self.add_file_option('--centroids')\n",
      "\n",
      "    def get_centroids(self):\n",
      "        f = open(self.options.centroids,'r')\n",
      "        centroids = pickle.load(f)\n",
      "        f.close()\n",
      "        return centroids\n",
      "\n",
      "    def mapper(self, _, line):\n",
      "        elements = line.split(',')\n",
      "\n",
      "        point = numpy.array([float(x) for x in elements[2:]])\n",
      "        centroids = self.get_centroids()\n",
      "        \n",
      "        distances = [numpy.linalg.norm(point - c) for c in centroids]\n",
      "        cluster = numpy.argmin(distances)\n",
      "\n",
      "        yield int(cluster), point.tolist()\n",
      "\n",
      "    def combiner(self, cluster, points):\n",
      "        s = numpy.array(points.next())\n",
      "        n = 1\n",
      "        for p in points:\n",
      "            s += p\n",
      "            n += 1\n",
      "\n",
      "        yield cluster, (s.tolist(), n)\n",
      "\n",
      "    def reducer(self, cluster, partial_sums):\n",
      "        SUM, N = partial_sums.next()\n",
      "        SUM = numpy.array(SUM)\n",
      "        for ps, n in partial_sums:\n",
      "            SUM += ps\n",
      "            N += n\n",
      "\n",
      "        yield cluster, (SUM / N).tolist()\n",
      "\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    update_centroids.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile kmeans.py\n",
      "#!/usr/bin/python\n",
      "import sys\n",
      "import random\n",
      "import numpy as np\n",
      "import numpy\n",
      "import pandas as pd\n",
      "import pickle \n",
      "\n",
      "from sys import stderr\n",
      "\n",
      "from mrjob.job import MRJob\n",
      "from init_centroids import find_initial_centroids\n",
      "from update_centroids import update_centroids\n",
      "\n",
      "\n",
      "def extract_centroids(job, runner):\n",
      "    c = []\n",
      "    for line in runner.stream_output():\n",
      "        key, value = job.parse_output_line(line)\n",
      "        print key, value\n",
      "        c.append(value)\n",
      "    return c\n",
      "\n",
      "def write_centroids_to_disk(centroids, fname):\n",
      "    f = open(fname,'w')\n",
      "    pickle.dump(centroids,f)\n",
      "    f.close()\n",
      "    \n",
      "def get_biggest_diff(centroids,new_centroids):\n",
      "    distances = [numpy.linalg.norm(numpy.array(c1) - c2) for c1,c2 in zip(centroids,new_centroids)]\n",
      "    max_d = max(distances)\n",
      "    return max_d\n",
      "CENTROIDS_FILE='centroids'\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    args = sys.argv[1:]\n",
      "    init_centroids_job = find_initial_centroids(args=args)\n",
      "    with init_centroids_job.make_runner() as init_runner:\n",
      "        init_runner.run()\n",
      "        \n",
      "        centroids = extract_centroids(init_centroids_job,init_runner)\n",
      "        write_centroids_to_disk(centroids, CENTROIDS_FILE)\n",
      "        i = 1\n",
      "        while True:\n",
      "            print \"Iteration #%i\" % i\n",
      "            update_centroids_job = update_centroids(args=args + ['--centroids='+CENTROIDS_FILE])\n",
      "            with update_centroids_job.make_runner() as update_centroids_runner:\n",
      "                update_centroids_runner.run()\n",
      "\n",
      "                new_centroids = extract_centroids(update_centroids_job, update_centroids_runner)\n",
      "                write_centroids_to_disk(new_centroids, CENTROIDS_FILE)\n",
      "\n",
      "                diff = get_biggest_diff(centroids, new_centroids)\n",
      "\n",
      "                if diff > 10.0:\n",
      "                    centroids = new_centroids\n",
      "                else:\n",
      "                    break\n",
      "\n",
      "                i+=1\n",
      "\n",
      "\n",
      "            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile assign_centers.py\n",
      "#!/usr/bin/python\n",
      "import sys\n",
      "import random\n",
      "import numpy\n",
      "import pickle\n",
      "from sys import stderr\n",
      "from mrjob.job import MRJob\n",
      "\n",
      "\n",
      "\n",
      "class assign_centroids(MRJob):\n",
      "    def configure_options(self):\n",
      "        super(assign_centroids, self).configure_options()\n",
      "        \n",
      "        self.add_file_option('--centroids')\n",
      "    def get_centroids(self):\n",
      "        f = open(self.options.centroids,'r')\n",
      "        centroids = pickle.load(f)\n",
      "        f.close()\n",
      "        return centroids\n",
      "\n",
      "    def mapper(self, _, line):\n",
      "        try:\n",
      "            elements = line.split(',')\n",
      "\n",
      "            point = numpy.array([float(x) for x in elements[2:]])\n",
      "\n",
      "            centroids = self.get_centroids()\n",
      "\n",
      "\n",
      "            distances = [numpy.linalg.norm(point - c) for c in centroids]\n",
      "            cluster = numpy.argmin(distances)\n",
      "\n",
      "            yield elements[1], int(cluster)\n",
      "        except Exception, e:\n",
      "            stderr.write('Error in line:\\n'+line)\n",
      "            stderr.write(e.message)\n",
      "            self.increment_counter('MrJob Counters','mapper-error',1)\n",
      "            yield (('error','mapper', str(e)), 1)\n",
      "\n",
      "\n",
      "    def reducer(self, station, cluster):\n",
      "        try:\n",
      "            yield station, list(cluster)\n",
      "        except Exception, e:\n",
      "            \n",
      "            stderr.write(e.message)\n",
      "            self.increment_counter('MrJob Counters','mapper-error',1)\n",
      "            yield (('error','mapper', str(e)), 1)\n",
      "\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    assign_centroids.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpl_toolkits.basemap import Basemap\n",
      "import matplotlib.pyplot as plt\n",
      "from scipy.interpolate import griddata\n",
      "\n",
      "lonmin=-180;lonmax=180;latsmin=-80;latsmax=80;\n",
      "plt.figure(figsize=(15,10),dpi=300)\n",
      "m = Basemap(projection='merc',llcrnrlat=latsmin,urcrnrlat=latsmax,\\\n",
      "            llcrnrlon=lonmin,urcrnrlon=lonmax,lat_ts=20,resolution='i')\n",
      "m.drawcoastlines(linewidth=0.5)#,color='grey')\n",
      "\n",
      "parallels = np.arange(-80,81,10.)\n",
      "m.drawparallels(parallels,labels=[False,True,True,False])\n",
      "meridians = np.arange(10.,351.,20.)\n",
      "m.drawmeridians(meridians,labels=[True,False,False,True])\n",
      "\n",
      "lats= merged_data.loc[:,'latitude'].values\n",
      "lons= merged_data.loc[:,'longitude'].values\n",
      "ll=len(lons)\n",
      "x, y = m(lons,lats)\n",
      "z= merged_data.loc[:,'cluster'].values\n",
      "m.scatter(x, y, c=z, s=10, cmap=plt.cm.jet, edgecolors='None')\n",
      "cbar = plt.colorbar()\n",
      "#plt.clim(-16,32)\n",
      "cbar.ax.set_ylabel('area index')\n",
      "plt.title('Eligible weather stations')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}